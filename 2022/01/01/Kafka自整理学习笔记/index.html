<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="前言  本博客整理了一些Kafka的基本概念和使用  自己用来当笔记的，故不需要图帮助理解  只有Java端的使用，C++端的以后可能会补上">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka自整理学习笔记">
<meta property="og:url" content="http://yoursite.com/2022/01/01/Kafka%E8%87%AA%E6%95%B4%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="MemoForward&#39;s Blog">
<meta property="og:description" content="前言  本博客整理了一些Kafka的基本概念和使用  自己用来当笔记的，故不需要图帮助理解  只有Java端的使用，C++端的以后可能会补上">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-01-01T03:30:14.000Z">
<meta property="article:modified_time" content="2022-11-14T13:38:53.082Z">
<meta property="article:author" content="MemoForward">
<meta property="article:tag" content="Java">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="中间件">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2022/01/01/Kafka%E8%87%AA%E6%95%B4%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>Kafka自整理学习笔记 | MemoForward's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="MemoForward's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">MemoForward's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">阿星的学习笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/MemoForward" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/01/Kafka%E8%87%AA%E6%95%B4%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/personal.png">
      <meta itemprop="name" content="MemoForward">
      <meta itemprop="description" content="一个温柔又专情的闷骚之人">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MemoForward's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka自整理学习笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-01 11:30:14" itemprop="dateCreated datePublished" datetime="2022-01-01T11:30:14+08:00">2022-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-11-14 21:38:53" itemprop="dateModified" datetime="2022-11-14T21:38:53+08:00">2022-11-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<ol>
<li><p>本博客整理了一些Kafka的基本概念和使用</p>
</li>
<li><p>自己用来当笔记的，故不需要图帮助理解</p>
</li>
<li>只有Java端的使用，C++端的以后可能会补上</li>
</ol>
</blockquote>
<a id="more"></a>
<h1 id="1-事件流"><a href="#1-事件流" class="headerlink" title="1. 事件流"></a>1. 事件流</h1><p>事件流的三个特征：数据格式+持续性的流+分发。</p>
<ul>
<li>实时从事件源读取事件流</li>
<li>数据持久化存储和恢复</li>
<li>实时或者异步处理和响应流数据</li>
<li>将数据流路由到不同的目的地</li>
</ul>
<h1 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="2. Kafka"></a>2. Kafka</h1><p>Kafka是一个数据流平台，其具有三个能力：</p>
<ol>
<li>发布和订阅事件流，可以持续地从其他系统导入和导出data</li>
<li>持久可靠地存储事件流</li>
<li>可以同步和异步化处理事件流</li>
</ol>
<p>以上的功能Kafka都能以<strong>分布式、高度可拓展、高容错、高安全</strong>的方式提供。</p>
<h1 id="3-Kafka如何工作"><a href="#3-Kafka如何工作" class="headerlink" title="3. Kafka如何工作"></a>3. Kafka如何工作</h1><p>Server和Clients通过高性能的TCP网络来进行通讯。</p>
<h2 id="3-1-Servers"><a href="#3-1-Servers" class="headerlink" title="3.1 Servers"></a>3.1 Servers</h2><p>​    可以通过集群进行部署，一个或者多个server都可以运行，用于存储的服务器称为brokers。kafka集群具有高度的可拓展性和容错能力，如何任何服务器发生故障，其他服务器将接管其工作。</p>
<h2 id="3-2-Clients"><a href="#3-2-Clients" class="headerlink" title="3.2 Clients"></a>3.2 Clients</h2><p>微服务或者分布式客户端并行地读取、写和处理事件流。</p>
<h2 id="3-3-主要概念和术语"><a href="#3-3-主要概念和术语" class="headerlink" title="3.3 主要概念和术语"></a>3.3 主要概念和术语</h2><p>​    事件（event）可以称之为消息。从kafka读取或者写入数据，数据要遵循一定的格式：概念上，一条消息要包含一个key，一个value、一个时间戳以及可选择的元数据信息。</p>
<p>​    在kafka中，生产者和消费者之间是独立的。生产者不必等待消费者消费数据，但Kafka会保证同一个消费者不会重复消费同一条数据。</p>
<p>​    消息会以Topic进行分组和永久存储。简单来说，Topic就像文件系统一个文件夹，消息就像是文件夹中的文件。一个Topic可以有多个生产者和多个消费者，<strong>消息被消费后不会删除</strong>，用户可以通过配置文件来决定就消息可以保存多久，但是磁盘上的消息数量不会影响kafka的性能。</p>
<p>​    一个Topic下有多个Partition（分区）。简单解释就是，一个topic里面的消息被拆分了，而且分布在了不同的broker上。这种分布式的结构在一定程度上实现了生产者和消费者同时进行消息的写入与读取。当一条消息被发布到了Topic中，它实际上是被加到了一个partition中。相同key的消息会被写入到同一个partition中，kafka保证任意消费者会严格按照消息的写入顺序来消费消息。为了保证数据的容错率和高可用性，每个Topic都有存有副本（每个partition分布在不同的broker，每个broker会存有其他partition数据的副本）</p>
<h1 id="4-安装"><a href="#4-安装" class="headerlink" title="4. 安装"></a>4. 安装</h1><p><strong>这里注意一样，kafka3.0号称不依赖zk了，但是我看了一下官网样例，还是写的带zk的部署方式，不依赖zk的只是有范本，还未有稳定版本。</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf kafka_2.13-3.0.0.tgz</span><br><span class="line"><span class="built_in">cd</span> kafka_2.13-3.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至少需要java8</span></span><br><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在另一台终端开启kafka broker</span></span><br><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure>
<h1 id="5-使用"><a href="#5-使用" class="headerlink" title="5. 使用"></a>5. 使用</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建topic</span></span><br><span class="line"><span class="comment"># 一个partition，一个副本，topic名称test</span></span><br><span class="line">./kafka-topics.sh --create --zookeeper ip:2182 --replication-factor 1 --partition 1 --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前kafka有多少topic</span></span><br><span class="line">./kafka-topics.sh --list --zookeeper ip:2182</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送消息</span></span><br><span class="line"><span class="comment"># kafka自带了一个producer客户端，可与从本地文件或者命令行中传递消息（把内容以消息的形式发送到kafka集群）</span></span><br><span class="line"><span class="comment"># 发送两条消息</span></span><br><span class="line">./kafka-console-producer.sh --broker-list ip:9092 --topic <span class="built_in">test</span></span><br><span class="line">&gt; message1</span><br><span class="line">&gt; message2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 消费消息</span></span><br><span class="line"><span class="comment"># kafka携带了一个命令行客户端，会将获取到内容在命令行输出，默认消费最新消息</span></span><br><span class="line"><span class="comment"># 方式一：从最后一条消息的偏移量+1开始消费</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server ip:9092 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 方式二：从头开始消费</span></span><br><span class="line">./kafka-console-consumer.sh --bootstarp-server ip:9092 --from-beginning --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<h2 id="5-1-消费者的几个注意点："><a href="#5-1-消费者的几个注意点：" class="headerlink" title="5.1 消费者的几个注意点："></a>5.1 消费者的几个注意点：</h2><ul>
<li>消息是持久化存储的</li>
<li>消费是顺序存储的，先进先出</li>
<li>消息有偏移量</li>
<li>消息可以指定偏移量进行消费</li>
</ul>
<h1 id="6-顺序消费原理"><a href="#6-顺序消费原理" class="headerlink" title="6. 顺序消费原理"></a>6. 顺序消费原理</h1><p>kafka安装时的配置文件中指定的<code>log.dir</code>是kafka保存消息的路径。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># log.dir 内部</span></span><br><span class="line">默认有一个主题：__consumer_offsets，这个主题有多个分区，里面存放着消费者维护的偏移量。</span><br><span class="line"><span class="comment"># 每个消费者消费到了某个partition的第几条数据(offset)会存储在这个主题里面，以便于恢复</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">test</span>主题：</span><br><span class="line">	- 00000.index <span class="comment"># offset position（段的偏移）</span></span><br><span class="line">	- 00000.log <span class="comment"># 消息本体</span></span><br><span class="line">	- 00000.timestamp</span><br><span class="line">	</span><br><span class="line"><span class="comment"># .log文件其实就是分段(segment)，分段文件的大小可以在server.properties里面配置，默认1GB</span></span><br><span class="line"><span class="comment"># 查看分段文件</span></span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files 00000.log --<span class="built_in">print</span>-data-log </span><br><span class="line"><span class="comment"># segment结构如下：</span></span><br><span class="line">	- offset: 相对于该分区的偏移值，可以理解成第几条消息</span><br><span class="line">	- position: 相对于当前segment的偏移值</span><br><span class="line">	- CreateTime: 记录创建的时间</span><br><span class="line">	- isValid: 表示key的长度</span><br><span class="line">	- valuesize: 表示value的长度</span><br><span class="line">	- magic: 本次发布的kafka服务协议版本号</span><br><span class="line">	- compressscodec: 压缩工具</span><br><span class="line">	- producedId: 生产者ID（用于幂等）</span><br><span class="line">	- sequence: 消息的序列号（用于幂等）</span><br><span class="line">	- payload: 表示具体的消息</span><br></pre></td></tr></table></figure>
<p>原理：</p>
<ul>
<li>生产者将消息发送给broker，broker将消息保存在本地的日志文件中</li>
<li>消息的保存是有时序的，通过offset偏移量来保证消息的有序性</li>
<li>消费者消费消息时也是通过offsets来描述当前要消费的那条消息的位置（offset+1）</li>
</ul>
<h1 id="7-单播消息和多播消息"><a href="#7-单播消息和多播消息" class="headerlink" title="7. 单播消息和多播消息"></a>7. 单播消息和多播消息</h1><p>在一个topic中，启动两个消费者，一个生产者，问：生产者发送消息，这条消息是否会被两个消费者消费？</p>
<h2 id="7-1-单播消息"><a href="#7-1-单播消息" class="headerlink" title="7.1 单播消息"></a>7.1 单播消息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单播消息</span></span><br><span class="line"><span class="comment"># consumer-1</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server ip:9092 --consumer-property group.id=testGroup --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># consumer-2</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server ip:9092 --consumer-property group.id=testGroup --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">&gt; 生产者发送了消息</span><br><span class="line">&gt; message1</span><br><span class="line">&gt; message2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发现消费者group中只有一个消费者会受到订阅的test主题的消息，而且这个消费者还不会变（因为test主题只有一个partition）</span></span><br><span class="line"><span class="comment"># 可以理解成这个消费者订阅了这个partition</span></span><br></pre></td></tr></table></figure>
<h2 id="7-2-多播消息"><a href="#7-2-多播消息" class="headerlink" title="7.2 多播消息"></a>7.2 多播消息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多播消息</span></span><br><span class="line"><span class="comment"># consumer-1</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server ip:9092 --consumer-property group.id=testGroup1 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># consumer-2</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server ip:9092 --consumer-property group.id=testGroup2 --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">&gt; 生产者发送了消息</span><br><span class="line">&gt; message1</span><br><span class="line">&gt; message2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个消费者都收到了消息</span></span><br></pre></td></tr></table></figure>
<h2 id="7-3-解释"><a href="#7-3-解释" class="headerlink" title="7.3 解释"></a>7.3 解释</h2><p>​    概念就是消费者组，一个消费者组可以看成是一个消费者，一个消费者是不能重复消费消息的，消费者组是为了满足并发消费消息，从而实现高吞吐的设计。一个partition效果不明显，但是当partition多了，一个消费者组中不同的消费者可以通过某个topic的消息效率。</p>
<h2 id="7-4-查看消费组及信息"><a href="#7-4-查看消费组及信息" class="headerlink" title="7.4 查看消费组及信息"></a>7.4 查看消费组及信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前节点下有多少消费者组</span></span><br><span class="line">./kafka-consumer-groups.sh --bootstrap-server ip:9092 --list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看消费者组中的具体信息：当前偏移量、最后一条消息的偏移量</span></span><br><span class="line">./kafka-consumer-groups.sh --bootstrap-server ip:9092 --describe --group testGroup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看到以下信息</span></span><br><span class="line">GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG(还有多少未被消费的消息) CONSUMER-ID  HOST CLIENT-ID</span><br><span class="line"><span class="comment"># 如果消费者挂了，以上信息依然会存在，生产者可以继续生产消息，但是CURRENT-OFFSET是不动的，因为消费者没有消费消息</span></span><br></pre></td></tr></table></figure>
<p>重点关注：</p>
<ul>
<li>CURRENT-OFFSET：最后被消费的消息的偏移量</li>
<li>LOG-END-OFFSET：最后一条消息的偏移量</li>
<li>LAG：当前消费组未消费的消息数量</li>
</ul>
<h1 id="8-主题与分区"><a href="#8-主题与分区" class="headerlink" title="8. 主题与分区"></a>8. 主题与分区</h1><h2 id="8-1-Topic"><a href="#8-1-Topic" class="headerlink" title="8.1 Topic"></a>8.1 Topic</h2><p>​    主题就是Kafka消息的<strong>逻辑</strong>划分，一个主题下相当与一个类别。Kafka通过Topic将消息进行分类，不同的Topic会被订阅该Topic的消费者消费。</p>
<p>​    如果一个Topic中的消息巨多无比（可能有几个T），而消息是会被保存到<code>.log</code>文件中的，用一个文件，压力太大。为了解决这个问题，kafka使用了partition来分布式存储这些消息。</p>
<h2 id="8-2-Partition"><a href="#8-2-Partition" class="headerlink" title="8.2 Partition"></a>8.2 Partition</h2><ul>
<li>分区存储，可以解决统一存储文件过大的问题</li>
<li>提高了读写的吞吐量</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主题多分区</span></span><br><span class="line">./kafka-topics.sh --create --zookeeper ip:2181 --replication-factor 1 --partitions 2 --topic test2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看log文件，可以看见如果有多个partition，一个topic其实就会有两个文件夹存在磁盘上</span></span><br><span class="line">test2-0</span><br><span class="line">	- 0000.index</span><br><span class="line">	- 0000.log</span><br><span class="line">	- 0000.timestamp</span><br><span class="line">	</span><br><span class="line">test2-1</span><br><span class="line">		- 0000.index</span><br><span class="line">	- 0000.log</span><br><span class="line">	- 0000.timestamp</span><br></pre></td></tr></table></figure>
<p><strong>小细节，大改变：</strong></p>
<ul>
<li>kafka内部默认有50个主题__consumer_offsets，这些主题用存储消费者消费消息的偏移量</li>
<li>消费者会定期把自己消费分区的offset提交给kafka内部的主题__consumer_offsets，提交的时候，key是<code>consumerGroupId+topic+分区号</code>，value是当前分区的offset。（消费者）</li>
<li>__conusmer_offsets有多个分区（可以server.properties里面配置，默认50），消费者通过<code>hash(consumerGroupId)%分区数</code>来确定消息被存储到哪个分区</li>
<li>kafka会定期消费已经消费过的数据，默认是7天，旧消息会被删除</li>
<li>__consumer_offsets里面有多个分区是为了提高并发效率，很多消费者可以同时写入自己的offset</li>
</ul>
<h1 id="9-集群与副本"><a href="#9-集群与副本" class="headerlink" title="9. 集群与副本"></a>9. 集群与副本</h1><h2 id="9-1-搭建集群（伪），三个broker"><a href="#9-1-搭建集群（伪），三个broker" class="headerlink" title="9.1 搭建集群（伪），三个broker"></a>9.1 搭建集群（伪），三个broker</h2><p>准备3个server.properties，这里演示建在一台机器上的伪集群</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># server.properties</span></span><br><span class="line">broker.id = 0</span><br><span class="line">listeners=PLAINEXT://ip:9092</span><br><span class="line">log.dir=/usr/<span class="built_in">local</span>/data/kafka-logs-0</span><br><span class="line"></span><br><span class="line"><span class="comment"># server1.properties</span></span><br><span class="line">broker.id = 1</span><br><span class="line">listeners=PLAINEXT://ip:9093</span><br><span class="line">log.dir=/usr/<span class="built_in">local</span>/data/kafka-logs-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># serve2r.properties</span></span><br><span class="line">broker.id = 2</span><br><span class="line">listeners=PLAINEXT://ip:9094</span><br><span class="line">log.dir=/usr/<span class="built_in">local</span>/data/kafka-logs-2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动三个kafka服务器</span></span><br><span class="line">bin/kafka-server-start.sh -deamon config/server.properties</span><br><span class="line">bin/kafka-server-start.sh -deamon config/server1.properties</span><br><span class="line">bin/kafka-server-start.sh -deamon config/server2.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以登录zkClient来看一下节点有没有顺利注册(brokers/ids下有三个znode(0, 1, 2))</span></span><br></pre></td></tr></table></figure>
<h2 id="9-2-副本的概念"><a href="#9-2-副本的概念" class="headerlink" title="9.2 副本的概念"></a>9.2 副本的概念</h2><p>​    副本是为主题中的分区创建多个备份，多个副本在Kafka集群中多个broker中，<strong>会有一个副本是Leader</strong>，其他是Follower，副本数量一般不超过Broker的数量，不然没有意义。</p>
<p>创建1个主题，2个分区，三个副本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create --zookeeper ip:2181 --replication-factor 3 --partitions 2 --topic my-replica-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主题</span></span><br><span class="line">./kafka-topics.sh --describe --zookeeper ip:2181 --topic my-replica-topic</span><br></pre></td></tr></table></figure>
<p>结构：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Topic:my-replica-topic</th>
<th>PartitionCount:2</th>
<th>ReplicationFactor:3</th>
<th>Configs:</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>- Topic：my-replica-topic</td>
<td>- Partition: 0</td>
<td>- Leader:2</td>
<td>Replicas: 2,0,1</td>
<td>lsr:2,0,1</td>
</tr>
<tr>
<td>- Topic：my-replica-topic</td>
<td>- Partition: 2</td>
<td>- Leader:0</td>
<td>Replicas: 0,1,2</td>
<td>lsr:0,1,2</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>Leader负责读写</strong>，Follower中的副本会同步Leader中的数据</li>
<li>不同Partition所在的Broker是不一样的</li>
<li>每个Partition的Leader可能都不一样，说明Leader不是Topic的概念。Leader所在Broker负责该Partition的读写，也负责Follower的数据同步</li>
<li>lsr：可以同步或者已经同步的节点存放在isr中，如果一个节点同步性能很差，该节点会被T掉</li>
<li>Leader挂掉，新Leader会在lsr集合中选举</li>
</ul>
<h1 id="10-Kafka集群的消息发送和消费"><a href="#10-Kafka集群的消息发送和消费" class="headerlink" title="10. Kafka集群的消息发送和消费"></a>10. Kafka集群的消息发送和消费</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发送</span></span><br><span class="line">./kafka-console-producer.sh --broker-list ip:9092.ip:9093,ip:9094 --topic my-replica-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单消费者</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-list ip:9092.ip:9093,ip:9094  --from-beginning --topic my-replica-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个组两个消费者</span></span><br><span class="line"><span class="comment"># 消费者1</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-list ip:9092.ip:9093,ip:9094 --consumer-property group.id=testGroup1 --from-beginning --topic my-replica-topic</span><br><span class="line"><span class="comment"># 消费者2</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-list ip:9092.ip:9093,ip:9094 --consumer-property group.id=testGroup1 --from-beginning --topic my-replica-topic</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ul>
<li>一个Partition最多被一个消费组里的一个消费者消费，因为要保证消息消费的顺序性（想想并发）</li>
<li>一个消费者可以消费多个Partition</li>
<li>Kafka只能保证Partition中局部的消息顺序，不能保证Topic中的消息顺序消费</li>
<li>消费组中的消费者的数量一般不会多于Partition的数量，因为会有消费者消费不到消息</li>
<li>如果某个消费者挂了，就会触发rebalance机制，让其他消费者消费其对应的partition</li>
</ul>
<h1 id="10-Kafka-Java生产者实现"><a href="#10-Kafka-Java生产者实现" class="headerlink" title="10. Kafka Java生产者实现"></a>10. Kafka Java生产者实现</h1><h2 id="10-1-实现"><a href="#10-1-实现" class="headerlink" title="10.1 实现"></a>10.1 实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 依赖</span></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;与kafka版本一致&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">            </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySimpleProducer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TOPIC_NAME = <span class="string">"memo-kafka-test"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 设置参数</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"192.168.1.249:9092,192.168.1.249:9093,192.168.1.249:9094"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 把key和value从字符串序列转成字节数组</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置同步消息的ack</span></span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG, <span class="string">"1"</span>);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也会造成消息的重复发送，</span></span><br><span class="line"><span class="comment">         * 如网络抖动，所以需要在接收者那边做好消息接收的幂等性处理</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG, <span class="number">3</span>);</span><br><span class="line">        <span class="comment">// 发送消息重试间隔时间，设为300</span></span><br><span class="line">        props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, <span class="number">300</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 设置消息发送的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区(默认32M)，</span></span><br><span class="line"><span class="comment">         * kafka生产者客户端会启一条本地线程拉16kb的数据发送给kafka，如果消息没达到16kb，该线程</span></span><br><span class="line"><span class="comment">         * 10毫秒以后也会将数据发送</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">10240</span>);</span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建生产消息的客户端，传入参数</span></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建消息</span></span><br><span class="line">        <span class="comment">// key的作用是决定往哪个分区上发，value是具体消息内容</span></span><br><span class="line">        ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC_NAME, <span class="string">"mytestKey"</span>, <span class="string">"hello kafka2"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 发送消息,得到消息发送的元数据并输出</span></span><br><span class="line">        RecordMetadata recordMetadata = producer.send(producerRecord).get();</span><br><span class="line">        System.out.println(<span class="string">"**********************************"</span>);</span><br><span class="line">        System.out.println(<span class="string">"同步方式发送结果："</span> + <span class="string">"topic-"</span> + recordMetadata.topic()</span><br><span class="line">                + <span class="string">"|partition-"</span> + recordMetadata.partition() + <span class="string">"|offset-"</span> + recordMetadata.offset());</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="10-2-同步发送和异步发送"><a href="#10-2-同步发送和异步发送" class="headerlink" title="10.2 同步发送和异步发送"></a>10.2 同步发送和异步发送</h2><p>同步发送和异步发送都是针对生产者和Kafka服务端的，同步用的比较多，异步的性能提升不明显，反而会出现消息丢失的可能。</p>
<h3 id="10-2-1-同步发送"><a href="#10-2-1-同步发送" class="headerlink" title="10.2.1 同步发送"></a>10.2.1 同步发送</h3><p>如果生产者发送消息，没有收到kafka给服务端的<code>ack</code>，生产者会阻塞，阻塞到3S的时间（可以配置），如果还没有收到消息，则会进行重试，重试的次数默认也为3个，还不行，就会报错了。</p>
<h3 id="10-2-2-异步发送"><a href="#10-2-2-异步发送" class="headerlink" title="10.2.2 异步发送"></a>10.2.2 异步发送</h3><p>不会确认收到kafka的<code>ack</code>，会触发一个回调函数（不会阻塞）。生产者发送完消息可以做别的事情，broker收到消息后就会触发回调（callback）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">producer.send(producerRecord, (recordMetadata, e) -&gt; &#123;</span><br><span class="line">               <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">                   System.err.println(<span class="string">"发送消息失败:"</span> + Arrays.toString(e.getStackTrace()));</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">if</span> (recordMetadata != <span class="keyword">null</span>) &#123;</span><br><span class="line">                   System.out.println(<span class="string">"异步方式发送结果："</span> + <span class="string">"topic-"</span> + recordMetadata.topic()</span><br><span class="line">                           + <span class="string">"|partition-"</span> + recordMetadata.partition() + <span class="string">"|offset-"</span> + recordMetadata.offset());</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h2 id="10-3-关于生产者ack配置"><a href="#10-3-关于生产者ack配置" class="headerlink" title="10.3 关于生产者ack配置"></a>10.3 关于生产者ack配置</h2><p><code>ack</code>就是在<strong>同步发送</strong>中，生产者给kafka发送消息后的，kafka给的一个确认信号。</p>
<p><code>ack</code>会有三个参数配置：</p>
<ul>
<li>ack=0：kafka不需要任何broker收到消息，会立即返回ack给生产者（最容易丢消息，但是效率最高）。</li>
<li>ack=1：leader已经收到消息，并把消息写入到本地的log中，才会返回ack生产者。性能和安全性是最均衡的。</li>
<li>ack=-1/all：里面有默认配置<code>min.insync.replicas=2(默认为1，推荐配置大于等于2)</code>，leader同步2个副本之后（此时集群中有2个broker已完成数据的接收），才会返回ack给生产者。最安全但性能最差。默认是1，那么和ack=1是一样的，因为leader本身就是1个副本。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置同步消息的ack</span></span><br><span class="line">     props.put(ProducerConfig.ACKS_CONFIG, <span class="string">"1"</span>);</span><br><span class="line">     <span class="comment">/*</span></span><br><span class="line"><span class="comment">      * 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也会造成消息的重复发送，</span></span><br><span class="line"><span class="comment">      * 如网络抖动，所以需要在接收者那边做好消息接收的幂等性处理</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">     props.put(ProducerConfig.RETRIES_CONFIG, <span class="number">3</span>);</span><br><span class="line">     <span class="comment">// 发送消息重试间隔时间，设为300</span></span><br><span class="line">     props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, <span class="number">300</span>);</span><br></pre></td></tr></table></figure>
<h2 id="10-4-关于消息发送的缓冲区"><a href="#10-4-关于消息发送的缓冲区" class="headerlink" title="10.4 关于消息发送的缓冲区"></a>10.4 关于消息发送的缓冲区</h2><ul>
<li>kafka默认会创建一个消息缓冲区，默认为32MB（可配置）</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 设置消息发送的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区(默认32M)，</span></span><br><span class="line"><span class="comment"> * kafka生产者客户端会启一条本地线程拉16kb的数据发送给kafka，如果消息没达到16kb，该线程</span></span><br><span class="line"><span class="comment"> * 10毫秒以后也会将数据发送</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>kafka客户端本地线程会去缓冲区一次拉16kb的数据，发送给broker</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>如果线程拉不到16kb的数据，间隔10ms也会发送给broker</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<h1 id="11-Java客户端消费者的实现"><a href="#11-Java客户端消费者的实现" class="headerlink" title="11. Java客户端消费者的实现"></a>11. Java客户端消费者的实现</h1><h2 id="11-1-实现"><a href="#11-1-实现" class="headerlink" title="11.1 实现"></a>11.1 实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 依赖也是kafka-clients</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySimpleConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TOPIC_NAME = <span class="string">"memo-kafka-test"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String CONSUMER_GROUP_NAME = <span class="string">"memoGroup"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 设置参数</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"192.168.1.249:9092,192.168.1.249:9093,192.168.1.249:9094"</span>);</span><br><span class="line">        <span class="comment">// 消费者组</span></span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        <span class="comment">// 开启offset自动提交，默认是true</span></span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"true"</span>);</span><br><span class="line">        <span class="comment">// 设置自动提交的时间间隔，默认1000ms</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 一次poll最大拉取消息的条数，可以根据消费的速度来设置，默认500</span></span><br><span class="line">        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">500</span>);</span><br><span class="line">        <span class="comment">// 如果两次poll的时间如果超过了30s的时间间隔，kafka会人认为其消费能力过弱，会把其T出消费者组，并把分区分给其他消费者（rebalance）。</span></span><br><span class="line">        props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, <span class="number">30</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// consumer给broker发送心跳的间隔时间</span></span><br><span class="line">        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line">        <span class="comment">// kafka如果10秒没有收到消费者的心跳，则会把消费者踢出消费组，进行rebalance</span></span><br><span class="line">        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="number">10</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 订阅主题列表</span></span><br><span class="line">        <span class="comment">// consumer.subscribe(Collections.singletonList(TOPIC_NAME));</span></span><br><span class="line">        <span class="comment">// 指定分区消费</span></span><br><span class="line">        consumer.assign(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>)));</span><br><span class="line">        <span class="comment">// 消息回溯消费</span></span><br><span class="line">        consumer.seekToBeginning(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>)));</span><br><span class="line">        <span class="comment">// 从partition1的offset=5开始消费</span></span><br><span class="line">        <span class="comment">//consumer.seek(new TopicPartition(TOPIC_NAME, 1), 5);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 从指定时间点开始消费</span></span><br><span class="line">        List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);</span><br><span class="line">        <span class="keyword">long</span> fetchDateTime = <span class="keyword">new</span> Date().getTime() - <span class="number">1000</span> * <span class="number">60</span> * <span class="number">60</span>;</span><br><span class="line">        Map&lt;TopicPartition, Long&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (PartitionInfo partition : topicPartitions) &#123;</span><br><span class="line">            map.put(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, partition.partition()), fetchDateTime);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        // 根据时间找偏移量</span></span><br><span class="line"><span class="comment">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);</span></span><br><span class="line"><span class="comment">        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123;</span></span><br><span class="line"><span class="comment">            TopicPartition topicPartition = entry.getKey();</span></span><br><span class="line"><span class="comment">            OffsetAndTimestamp offsetAndTimestamp = entry.getValue();</span></span><br><span class="line"><span class="comment">            if (topicPartition == null || offsetAndTimestamp == null) continue;</span></span><br><span class="line"><span class="comment">            long offset = offsetAndTimestamp.offset();</span></span><br><span class="line"><span class="comment">            System.out.println("partition-" + topicPartition.partition() + "|offset-" + offset);</span></span><br><span class="line"><span class="comment">            // 指定offset开始消息</span></span><br><span class="line"><span class="comment">            consumer.assign(Collections.singletonList(topicPartition));</span></span><br><span class="line"><span class="comment">            consumer.seek(topicPartition, offset);</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 3. poll() API是拉取消息的长轮询,如果poll在1000ms内没有拉满，就会在1000ms之内一直等待</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                <span class="comment">// 消费</span></span><br><span class="line">                System.out.printf(<span class="string">"收到消息: partition=%d, offset=%d, key=%s, value=%s%n"</span>,</span><br><span class="line">                        record.partition(), record.offset(), record.key(), record.value());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">            // 消费结束后</span></span><br><span class="line"><span class="comment">            if (!records.isEmpty()) &#123;</span></span><br><span class="line"><span class="comment">                // 同步提交，当前线程会阻塞到offset提交成功</span></span><br><span class="line"><span class="comment">                // consumer.commitAsync();</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">                // 异步提交</span></span><br><span class="line"><span class="comment">                consumer.commitAsync((map, e) -&gt; &#123;</span></span><br><span class="line"><span class="comment">                    if (e != null) &#123;</span></span><br><span class="line"><span class="comment">                        e.printStackTrace();</span></span><br><span class="line"><span class="comment">                    &#125;</span></span><br><span class="line"><span class="comment">                &#125;);</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="11-2-消费者的自动提交和手动提交"><a href="#11-2-消费者的自动提交和手动提交" class="headerlink" title="11.2 消费者的自动提交和手动提交"></a>11.2 消费者的自动提交和手动提交</h2><p>消费者无论是自动提交还是手动提交，都需要把所属的<strong>消费组+消费的某个主题+消费的某个分区及消费的偏移量</strong>，这样的信息提交到集群的__consuemr_offset主题里面。</p>
<p>详细点来：消费者会把offset提交到borker-0上的__consumer_offset主题上，这个broker-0是一个controller。消费者要根据offset进行消费，消费者是先把消息给poll下来，然后不管有没有消费，就会定时把当前偏移量给提交给offset主题（自动提交）；手动提交就是把消息消费时或者消费完再手动提交offset。</p>
<h3 id="11-2-1-自动提交"><a href="#11-2-1-自动提交" class="headerlink" title="11.2.1 自动提交"></a>11.2.1 自动提交</h3><p>消费者poll到消息后默认情况下，会自动向broker的__consumer_offset主题提交当前主题-分区消费的偏移量。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启offset自动提交，默认是true</span></span><br><span class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"true"</span>);</span><br><span class="line"><span class="comment">// 设置自动提交的时间间隔，默认1000ms</span></span><br><span class="line">props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string">"1000"</span>);</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong>自动提交可能会丢消息，当消费者刚提交offset之后，没来得及消费就挂了，下一个消费者会从已经提交的offset的下一个位置开始消费消息。未被消费的消息就丢失掉了。</p>
<h3 id="11-2-2-手动提交"><a href="#11-2-2-手动提交" class="headerlink" title="11.2.2 手动提交"></a>11.2.2 手动提交</h3><ul>
<li>设置手动提交参数</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启offset手动提交</span></span><br><span class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"false"</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>手动同步提交</li>
</ul>
<p>会等待broker-0返回ack</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消费结束后</span></span><br><span class="line"><span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">	<span class="comment">// 同步提交，当前线程会阻塞到offset提交成功</span></span><br><span class="line">	consumer.commitAsync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>手动异步提交</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消费结束后</span></span><br><span class="line"><span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">	<span class="comment">// 异步提交</span></span><br><span class="line">	consumer.commitAsync((map, e) -&gt; &#123;</span><br><span class="line">		<span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 异步提交失败处理逻辑</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="11-3-长轮询消息"><a href="#11-3-长轮询消息" class="headerlink" title="11.3 长轮询消息"></a>11.3 长轮询消息</h2><ul>
<li>默认情况下，消费者一次会poll500条消息</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一次poll最大拉取消息的条数，可以根据消费的速度来设置，默认500</span></span><br><span class="line">props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">500</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>代码中设置了长轮询的时间是1000ms</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 3. poll() API是拉取消息的长轮询,如果poll在1000ms内没有拉到数据，则返回空</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br></pre></td></tr></table></figure>
<p>意味着：</p>
<ul>
<li><ul>
<li>如果一次poll到了数据，最大为500条，就会直接执行for循环</li>
<li>如果1000ms内没poll到数据，则返回空</li>
</ul>
</li>
<li><p>如果两次poll的时间间隔太长（默认30s），消费者会被kafkaT出消费者组</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果两次poll的时间如果超过了30s的时间间隔，kafka会人认为其消费能力过弱，会把其T出消费者组，并把分区分给其他消费者（rebalance）。</span></span><br><span class="line">props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, <span class="number">30</span> * <span class="number">1000</span>);</span><br></pre></td></tr></table></figure>
<h1 id="12-消费者的其他配置"><a href="#12-消费者的其他配置" class="headerlink" title="12. 消费者的其他配置"></a>12. 消费者的其他配置</h1><h2 id="12-1-健康状态检查"><a href="#12-1-健康状态检查" class="headerlink" title="12.1 健康状态检查"></a>12.1 健康状态检查</h2><p>消费者每隔1s像kafka集群发送心跳，集群发现如果有10s没有续约的消费者，将被T出消费组，触发该消费组的rebalance。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// consumer给broker发送心跳的间隔时间</span></span><br><span class="line">props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line"><span class="comment">// kafka如果10秒没有收到消费者的心跳，则会把消费者踢出消费组，进行rebalance</span></span><br><span class="line">props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="number">10</span> * <span class="number">1000</span>);</span><br></pre></td></tr></table></figure>
<h2 id="12-2-指定分区消费"><a href="#12-2-指定分区消费" class="headerlink" title="12.2 指定分区消费"></a>12.2 指定分区消费</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定分区消费</span></span><br><span class="line">consumer.assign(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">0</span>)));</span><br></pre></td></tr></table></figure>
<h2 id="12-3-消息回溯消费"><a href="#12-3-消息回溯消费" class="headerlink" title="12.3 消息回溯消费"></a>12.3 消息回溯消费</h2><p>每次消费都从offset=0开始消费，需要先指定分区，再seek</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定分区消费</span></span><br><span class="line">consumer.assign(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>)));</span><br><span class="line"><span class="comment">// 消息回溯消费</span></span><br><span class="line">onsumer.seekToBeginning(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>)));</span><br></pre></td></tr></table></figure>
<h2 id="12-4-指定offset消费"><a href="#12-4-指定offset消费" class="headerlink" title="12.4 指定offset消费"></a>12.4 指定offset消费</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定分区消费</span></span><br><span class="line">consumer.assign(Collections.singleton(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>)));</span><br><span class="line"><span class="comment">// 消息回溯消费</span></span><br><span class="line"><span class="comment">// consumer.seekToBeginning(Collections.singleton(new TopicPartition(TOPIC_NAME, 1)));</span></span><br><span class="line"><span class="comment">// 从partition1的offset=5开始消费</span></span><br><span class="line">consumer.seek(<span class="keyword">new</span> TopicPartition(TOPIC_NAME, <span class="number">1</span>), <span class="number">5</span>);</span><br></pre></td></tr></table></figure>
<h2 id="12-5-从指定时间点开始消费"><a href="#12-5-从指定时间点开始消费" class="headerlink" title="12.5 从指定时间点开始消费"></a>12.5 从指定时间点开始消费</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据时间找偏移量</span></span><br><span class="line">Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);</span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123;</span><br><span class="line">	TopicPartition topicPartition = entry.getKey();</span><br><span class="line">	OffsetAndTimestamp offsetAndTimestamp = entry.getValue();</span><br><span class="line">	<span class="keyword">if</span> (topicPartition == <span class="keyword">null</span> || offsetAndTimestamp == <span class="keyword">null</span>) <span class="keyword">continue</span>;</span><br><span class="line">	<span class="keyword">long</span> offset = offsetAndTimestamp.offset();</span><br><span class="line">	System.out.println(<span class="string">"partition-"</span> + topicPartition.partition() + <span class="string">"|offset-"</span> + offset);</span><br><span class="line">	<span class="comment">// 指定offset开始消息</span></span><br><span class="line">	consumer.assign(Collections.singletonList(topicPartition));</span><br><span class="line">	consumer.seek(topicPartition, offset);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="12-6-新消费者组的offset"><a href="#12-6-新消费者组的offset" class="headerlink" title="12.6 新消费者组的offset"></a>12.6 新消费者组的offset</h2><p>之前命令行的时候搞过的就是这个<code>--from-beginning</code>还记得吗。</p>
<p>默认的消费是最后的<code>offset+1</code>。知道这个就可以理解这个配置了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* latest(默认)：新消费者组从最后offset+1开始消费</span></span><br><span class="line"><span class="comment">* earliest：第一次从头，然后跟着offset，注意和seekBeginning区分</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br></pre></td></tr></table></figure>
<h1 id="13-SpringBoot集成Kafka"><a href="#13-SpringBoot集成Kafka" class="headerlink" title="13. SpringBoot集成Kafka"></a>13. SpringBoot集成Kafka</h1><h2 id="13-1-基本配置"><a href="#13-1-基本配置" class="headerlink" title="13.1 基本配置"></a>13.1 基本配置</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">依赖</span></span><br><span class="line"><span class="string">&lt;dependency&gt;</span></span><br><span class="line">	<span class="string">&lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;</span></span><br><span class="line">	<span class="string">&lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;</span></span><br><span class="line"><span class="string">&lt;/dependency&gt;</span></span><br><span class="line">      </span><br><span class="line"><span class="string">//</span> <span class="string">配置</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">bootstrap-servers:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.249</span><span class="string">:9092,192.168.1.249:9093,192.168.1.249:9094</span></span><br><span class="line">    <span class="attr">producer:</span></span><br><span class="line">      <span class="attr">retries:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">batch-size:</span> <span class="number">16384</span> <span class="comment"># 16k</span></span><br><span class="line">      <span class="attr">buffer-memory:</span> <span class="number">33554432</span> <span class="comment"># 32M</span></span><br><span class="line">      <span class="attr">acks:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">key-serializer:</span> <span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line">      <span class="attr">value-serializer:</span> <span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line">    <span class="attr">consumer:</span></span><br><span class="line">      <span class="attr">group-id:</span> <span class="string">default-group</span></span><br><span class="line">      <span class="attr">enable-auto-commit:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">auto-offset-reset:</span> <span class="string">earliest</span></span><br><span class="line">      <span class="attr">key-deserializer:</span> <span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line">      <span class="attr">value-deserializer:</span> <span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line">      <span class="attr">max-poll-records:</span> <span class="number">500</span></span><br><span class="line">    <span class="attr">listener:</span></span><br><span class="line">      <span class="comment"># TIME: 当一批poll()的数据被消费者Listener处理后，距离上次提交时间大于TIME时提交offset</span></span><br><span class="line">      <span class="comment"># COUNT: 当一批poll()的数据被消费者Listener处理后，处理record数量大于等于COUNT时提交offset</span></span><br><span class="line">      <span class="comment"># COUNT_TIME: 满足TIME或者COUNT</span></span><br><span class="line">      <span class="comment"># MANUAL: 当一批poll()的数据被消费者Listener处理后，手动调用acknowledge()提交offset</span></span><br><span class="line">      <span class="comment"># BATCH：当一批poll()数据被消费者Listener处理后，自动提交offset</span></span><br><span class="line">      <span class="comment"># record：当每一条记录被处理后，自动提交offset</span></span><br><span class="line">      <span class="attr">ack-mode:</span> <span class="string">MANUAL_IMMEDIATE</span> <span class="comment"># 手动调用acknowledge()后（处理一条消息后），提交offset</span></span><br></pre></td></tr></table></figure>
<h2 id="13-2-生产者"><a href="#13-2-生产者" class="headerlink" title="13.2 生产者"></a>13.2 生产者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/msg"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyKafkaController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TOPIC_NAME = <span class="string">"memo-kafka-test"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/send"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sendMessage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        kafkaTemplate.send(TOPIC_NAME, <span class="string">"KEY"</span>, <span class="string">"this kafka sb test msg!"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"success"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="13-3-消费者"><a href="#13-3-消费者" class="headerlink" title="13.3 消费者"></a>13.3 消费者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyConsumer</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 这里是一条条处理的，一次poll的消息有很多，这里一条条消费啦，thanks for springboot</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> record：收到的消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> ack: 针对手动提交很作用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@KafkaListener</span>(topics = <span class="string">"memo-kafka-test"</span>, groupId = <span class="string">"memoGroup1"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listenGroup</span><span class="params">(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack)</span> </span>&#123;</span><br><span class="line">        String value = record.value();</span><br><span class="line">        System.out.println(value);</span><br><span class="line">        System.out.println(record);</span><br><span class="line">        <span class="comment">// 手动提交offset</span></span><br><span class="line">        ack.acknowledge();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="13-4-消费者的详细配置"><a href="#13-4-消费者的详细配置" class="headerlink" title="13.4 消费者的详细配置"></a>13.4 消费者的详细配置</h1><h3 id="13-4-1-设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）"><a href="#13-4-1-设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）" class="headerlink" title="13.4.1 设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）"></a>13.4.1 设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">// 1个消费者，消费"memo-kafka-test"两个分区，"test"一个分区（并从offset=1开始消费） </span></span><br><span class="line"><span class="meta">@KafkaListener</span>(groupId = <span class="string">"memoGroup2"</span>, topicPartitions = &#123;</span><br><span class="line">           <span class="meta">@TopicPartition</span>(topic = <span class="string">"memo-kafka-test"</span>, partitions = &#123;<span class="string">"0"</span>, <span class="string">"1"</span>&#125;),</span><br><span class="line">           <span class="meta">@TopicPartition</span>(topic = <span class="string">"test"</span>, partitionOffsets = <span class="meta">@PartitionOffset</span>(partition = <span class="string">"0"</span>,initialOffset = <span class="string">"1"</span>))</span><br><span class="line">   &#125;, concurrency = <span class="string">"1"</span>)<span class="comment">// concurrency 就是同组下的消费者个数，就是并发消费数，建议小于等于分区总数</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listenGroupPro</span><span class="params">(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack)</span> </span>&#123;</span><br><span class="line">       String value = record.value();</span><br><span class="line">       System.out.println(value);</span><br><span class="line">       System.out.println(record);</span><br><span class="line">       <span class="comment">// 手动提交offset</span></span><br><span class="line">       ack.acknowledge();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h3 id="13-4-2-一些有关Listener的配置"><a href="#13-4-2-一些有关Listener的配置" class="headerlink" title="13.4.2 一些有关Listener的配置"></a>13.4.2 一些有关Listener的配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">listener:</span></span><br><span class="line">  <span class="comment"># TIME: 当一批poll()的数据被消费者Listener处理后，距离上次提交时间大于TIME时提交offset</span></span><br><span class="line">  <span class="comment"># COUNT: 当一批poll()的数据被消费者Listener处理后，处理record数量大于等于COUNT时提交offset</span></span><br><span class="line">  <span class="comment"># COUNT_TIME: 满足TIME或者COUNT</span></span><br><span class="line">  <span class="comment"># MANUAL: 当一批poll()的数据被消费者Listener处理后，手动调用acknowledge()提交offset</span></span><br><span class="line">  <span class="comment"># BATCH：当一批poll()数据被消费者Listener处理后，自动提交offset</span></span><br><span class="line">  <span class="comment"># record：当每一条记录被处理后，自动提交offset</span></span><br><span class="line">  <span class="attr">ack-mode:</span> <span class="string">MANUAL_IMMEDIATE</span> <span class="comment"># 手动调用acknowledge()后（处理一条消息后），提交offset</span></span><br></pre></td></tr></table></figure>
<h1 id="14-Kafka集群Controller、Rebalance、HW和LEO"><a href="#14-Kafka集群Controller、Rebalance、HW和LEO" class="headerlink" title="14. Kafka集群Controller、Rebalance、HW和LEO"></a>14. Kafka集群Controller、Rebalance、HW和LEO</h1><h2 id="14-1-Controller"><a href="#14-1-Controller" class="headerlink" title="14.1 Controller"></a>14.1 Controller</h2><p>​    <strong>kafka启动的时候会先向zookeeper创建一个临时序号节点，获得的序号最小的那个broker作为集群的controller，</strong>负责管理整个集群中的所有分区和副本的状态：</p>
<ul>
<li>当某个分区的leader出现故障时，由controller负责为该分区选举新的leader副本</li>
<li>当检测到某个分区的ISR集合发生变化时（broker新增或减少），由controller负责通知所有broker更新其元数据信息</li>
<li>当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由controller通知其他broker</li>
</ul>
<h2 id="14-2-Rebalance"><a href="#14-2-Rebalance" class="headerlink" title="14.2 Rebalance"></a>14.2 Rebalance</h2><p>前提时：消费者没有指明分区消费。当消费组里的消费者和分区关系发生变化，那么就会触发rebalance机制。</p>
<p>这个机制会重新调整消费者消费哪个分区。</p>
<p>在触发rebalance机制之前，消费者消费哪个分区有三种策略：</p>
<ul>
<li>range：通过公式来计算某个消费者消费哪个分区</li>
<li>轮询：大家轮着消费</li>
<li>sticky：在触发了rebalance之后，在消费者消费的原分区不变的基础上进行调整</li>
</ul>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>MemoForward
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2022/01/01/Kafka%E8%87%AA%E6%95%B4%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Kafka自整理学习笔记">http://yoursite.com/2022/01/01/Kafka自整理学习笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Java/" rel="tag"># Java</a>
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
              <a href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" rel="tag"># 中间件</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/01/git%E7%94%A8%E6%B3%95%E6%B5%85%E6%9E%90/" rel="prev" title="git用法浅析">
      <i class="fa fa-chevron-left"></i> git用法浅析
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/15/NIO%E5%9F%BA%E7%A1%80/" rel="next" title="NIO基础">
      NIO基础 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-事件流"><span class="nav-number">2.</span> <span class="nav-text">1. 事件流</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Kafka"><span class="nav-number">3.</span> <span class="nav-text">2. Kafka</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Kafka如何工作"><span class="nav-number">4.</span> <span class="nav-text">3. Kafka如何工作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Servers"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 Servers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Clients"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 Clients</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-主要概念和术语"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 主要概念和术语</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-安装"><span class="nav-number">5.</span> <span class="nav-text">4. 安装</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-使用"><span class="nav-number">6.</span> <span class="nav-text">5. 使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-消费者的几个注意点："><span class="nav-number">6.1.</span> <span class="nav-text">5.1 消费者的几个注意点：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-顺序消费原理"><span class="nav-number">7.</span> <span class="nav-text">6. 顺序消费原理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-单播消息和多播消息"><span class="nav-number">8.</span> <span class="nav-text">7. 单播消息和多播消息</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-单播消息"><span class="nav-number">8.1.</span> <span class="nav-text">7.1 单播消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-多播消息"><span class="nav-number">8.2.</span> <span class="nav-text">7.2 多播消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-解释"><span class="nav-number">8.3.</span> <span class="nav-text">7.3 解释</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-4-查看消费组及信息"><span class="nav-number">8.4.</span> <span class="nav-text">7.4 查看消费组及信息</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-主题与分区"><span class="nav-number">9.</span> <span class="nav-text">8. 主题与分区</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-1-Topic"><span class="nav-number">9.1.</span> <span class="nav-text">8.1 Topic</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-2-Partition"><span class="nav-number">9.2.</span> <span class="nav-text">8.2 Partition</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9-集群与副本"><span class="nav-number">10.</span> <span class="nav-text">9. 集群与副本</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#9-1-搭建集群（伪），三个broker"><span class="nav-number">10.1.</span> <span class="nav-text">9.1 搭建集群（伪），三个broker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-2-副本的概念"><span class="nav-number">10.2.</span> <span class="nav-text">9.2 副本的概念</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-Kafka集群的消息发送和消费"><span class="nav-number">11.</span> <span class="nav-text">10. Kafka集群的消息发送和消费</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-Kafka-Java生产者实现"><span class="nav-number">12.</span> <span class="nav-text">10. Kafka Java生产者实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#10-1-实现"><span class="nav-number">12.1.</span> <span class="nav-text">10.1 实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-2-同步发送和异步发送"><span class="nav-number">12.2.</span> <span class="nav-text">10.2 同步发送和异步发送</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-1-同步发送"><span class="nav-number">12.2.1.</span> <span class="nav-text">10.2.1 同步发送</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-2-异步发送"><span class="nav-number">12.2.2.</span> <span class="nav-text">10.2.2 异步发送</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-3-关于生产者ack配置"><span class="nav-number">12.3.</span> <span class="nav-text">10.3 关于生产者ack配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-4-关于消息发送的缓冲区"><span class="nav-number">12.4.</span> <span class="nav-text">10.4 关于消息发送的缓冲区</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11-Java客户端消费者的实现"><span class="nav-number">13.</span> <span class="nav-text">11. Java客户端消费者的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#11-1-实现"><span class="nav-number">13.1.</span> <span class="nav-text">11.1 实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-2-消费者的自动提交和手动提交"><span class="nav-number">13.2.</span> <span class="nav-text">11.2 消费者的自动提交和手动提交</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#11-2-1-自动提交"><span class="nav-number">13.2.1.</span> <span class="nav-text">11.2.1 自动提交</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-2-2-手动提交"><span class="nav-number">13.2.2.</span> <span class="nav-text">11.2.2 手动提交</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-3-长轮询消息"><span class="nav-number">13.3.</span> <span class="nav-text">11.3 长轮询消息</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12-消费者的其他配置"><span class="nav-number">14.</span> <span class="nav-text">12. 消费者的其他配置</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#12-1-健康状态检查"><span class="nav-number">14.1.</span> <span class="nav-text">12.1 健康状态检查</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-2-指定分区消费"><span class="nav-number">14.2.</span> <span class="nav-text">12.2 指定分区消费</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-3-消息回溯消费"><span class="nav-number">14.3.</span> <span class="nav-text">12.3 消息回溯消费</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-4-指定offset消费"><span class="nav-number">14.4.</span> <span class="nav-text">12.4 指定offset消费</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-5-从指定时间点开始消费"><span class="nav-number">14.5.</span> <span class="nav-text">12.5 从指定时间点开始消费</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-6-新消费者组的offset"><span class="nav-number">14.6.</span> <span class="nav-text">12.6 新消费者组的offset</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13-SpringBoot集成Kafka"><span class="nav-number">15.</span> <span class="nav-text">13. SpringBoot集成Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#13-1-基本配置"><span class="nav-number">15.1.</span> <span class="nav-text">13.1 基本配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-2-生产者"><span class="nav-number">15.2.</span> <span class="nav-text">13.2 生产者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-3-消费者"><span class="nav-number">15.3.</span> <span class="nav-text">13.3 消费者</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13-4-消费者的详细配置"><span class="nav-number">16.</span> <span class="nav-text">13.4 消费者的详细配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#13-4-1-设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）"><span class="nav-number">16.0.1.</span> <span class="nav-text">13.4.1 设置多主题，指定分区，指定offset，同组下的消费者个数（并发消费数）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-4-2-一些有关Listener的配置"><span class="nav-number">16.0.2.</span> <span class="nav-text">13.4.2 一些有关Listener的配置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-Kafka集群Controller、Rebalance、HW和LEO"><span class="nav-number">17.</span> <span class="nav-text">14. Kafka集群Controller、Rebalance、HW和LEO</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#14-1-Controller"><span class="nav-number">17.1.</span> <span class="nav-text">14.1 Controller</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14-2-Rebalance"><span class="nav-number">17.2.</span> <span class="nav-text">14.2 Rebalance</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="MemoForward"
      src="/images/personal.png">
  <p class="site-author-name" itemprop="name">MemoForward</p>
  <div class="site-description" itemprop="description">一个温柔又专情的闷骚之人</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/MemoForward" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;MemoForward" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/qq_34294121" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_34294121" rel="noopener" target="_blank"><i class="fa fa-fw fa-crosshairs"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="/chenxingyu@bupt.edu.cn" title="E-Mail → chenxingyu@bupt.edu.cn"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/memoforward" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;memoforward" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">MemoForward</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='137' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      script.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4a4e80d6432798f5c023',
      clientSecret: 'ef38d73f2ebc13d42df25af78048c374729dceed',
      repo        : 'memoforward.github.io',
      owner       : 'MemoForward',
      admin       : ['MemoForward'],
      id          : '340102c65690293d0b26dfdbee266f7a',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
